source('~/.active-rstudio-document')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "*", xmlValue)
root <- xmlRoot(parsedHtml)
children <- xmlChildren(root)
children[[1]]
source('~/.active-rstudio-document')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "*", xmlValue)
root <- xmlRoot(parsedHtml)
children <- xmlChildren(root)
nchar(capture.output(doc)[10])
source('~/.active-rstudio-document')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "*", xmlValue)
root <- xmlRoot(parsedHtml)
children <- xmlChildren(root)
root
nchar(capture.output(doc)[10])
source('~/.active-rstudio-document')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "*", xmlValue)
root <- xmlRoot(parsedHtml)
children <- xmlChildren(root)
root
nchar(capture.output(doc)[9])
source('~/.active-rstudio-document')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "*", xmlValue)
root <- xmlRoot(parsedHtml)
children <- xmlChildren(root)
root
nchar(capture.output(doc)[8])
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "*", xmlValue)
root <- xmlRoot(parsedHtml)
children <- xmlChildren(root)
root
for (i in 1:xmlSize(root)) {
capture.output(doc)[i]
nchar(capture.output(doc)[i])
}
source('~/.active-rstudio-document')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "*", xmlValue)
root <- xmlRoot(parsedHtml)
children <- xmlChildren(root)
root
for (i in xmlSize(root)) {
capture.output(doc)[i]
nchar(capture.output(doc)[i])
}
source('~/.active-rstudio-document')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "*", xmlValue)
root <- xmlRoot(parsedHtml)
children <- xmlChildren(root)
root
for (i in 1:100) {
capture.output(doc)[i]
nchar(capture.output(doc)[i])
}
source('~/.active-rstudio-document')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "*", xmlValue)
root <- xmlRoot(parsedHtml)
children <- xmlChildren(root)
capture.output(doc)[10]
for (i in 1:100) {
capture.output(doc)[i]
nchar(capture.output(doc)[i])
}
source('~/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/question4.R')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "*", xmlValue)
root <- xmlRoot(parsedHtml)
children <- xmlChildren(root)
capture.output(doc)[10]
nchar(capture.output(doc)[10])
for (i in 1:100) {
capture.output(doc)[i]
nchar(capture.output(doc)[i])
}
source('~/.active-rstudio-document')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "*", xmlValue)
root <- xmlRoot(parsedHtml)
children <- xmlChildren(root)
capture.output(doc)[100]
nchar(capture.output(doc)[100])
for (i in 1:100) {
capture.output(doc)[i]
nchar(capture.output(doc)[i])
}
source('~/.active-rstudio-document')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "*", xmlValue)
root <- xmlRoot(parsedHtml)
children <- xmlChildren(root)
capture.output(root)[100]
nchar(capture.output(root)[100])
source('~/.active-rstudio-document')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "*", xmlValue)
root <- xmlRoot(parsedHtml)
children <- xmlChildren(root)
capture.output(root)[10]
nchar(capture.output(root)[10])
source('~/.active-rstudio-document')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
plain.text <- xpathSApply(parsedHtml, "//text()[not(ancestor::script)][not(ancestor::style)][not(ancestor::noscript)][not(ancestor::form)]", xmlValue)
cat(paste(plain.text, collapse = " "))
#xpathSApply(parsedHtml, "*", xmlValue)
#root <- xmlRoot(parsedHtml)
#children <- xmlChildren(root)
capture.output(plain.text)[10]
nchar(capture.output(plain.text)[10])
source('~/.active-rstudio-document')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
plain.text <- xpathSApply(doc, "//p", xmlValue)
cat(paste(plain.text, collapse = "\n"))
#xpathSApply(parsedHtml, "*", xmlValue)
#root <- xmlRoot(parsedHtml)
#children <- xmlChildren(root)
capture.output(plain.text)[10]
nchar(capture.output(plain.text)[10])
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
plain.text <- xpathSApply(parsedHtml, "//p", xmlValue)
cat(paste(plain.text, collapse = "\n"))
#xpathSApply(parsedHtml, "*", xmlValue)
#root <- xmlRoot(parsedHtml)
#children <- xmlChildren(root)
capture.output(plain.text)[10]
nchar(capture.output(plain.text)[10])
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
fileURL <- "http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
dataDir <- "/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data"
if (!file.exists(dataDir)) {
dir.create(dataDir)
}
download.file(fileURL, "/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data/fwf.for")
DF <- read.fwf("/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data/fwf.for",
1, header = FALSE, sep = "\t",)
head(DF)
source('~/.active-rstudio-document')
fileURL <- "http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
dataDir <- "/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data"
if (!file.exists(dataDir)) {
dir.create(dataDir)
}
download.file(fileURL, "/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data/fwf.for")
DF <- read.fwf("/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data/fwf.for",skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(x)
source('~/.active-rstudio-document')
fileURL <- "http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
dataDir <- "/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data"
if (!file.exists(dataDir)) {
dir.create(dataDir)
}
download.file(fileURL, "/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data/fwf.for")
DF <- read.fwf("/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data/fwf.for",skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(DF)
sum(DF[,4])
sum(DF[,4]) + sum(DF[9])
source('~/.active-rstudio-document')
fileURL <- "http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
#dataDir <- "/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data"
#if (!file.exists(dataDir)) {
#  dir.create(dataDir)
#}
#download.file(fileURL, "/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data/fwf.for")
DF <- read.fwf("/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data/getdata-wksst8110.for",skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(DF)
sum(DF[,4]) + sum(DF[9])
sum(DF[4] + DF[9])
sum(DF[4])
sum(DF[9])
DF[4]
DF
c4 <- DT[4]
c9 <- DT[9]
c4+c9
sum(c4)
DT[4]
DT[,4]
source('~/.active-rstudio-document')
fileURL <- "http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
#dataDir <- "/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data"
#if (!file.exists(dataDir)) {
#  dir.create(dataDir)
#}
#download.file(fileURL, "/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data/fwf.for")
DF <- read.fwf("/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data/getdata-wksst8110.for",skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(DF)
#sum(DF[,4]) + sum(DF[9])
sum(DF[,4]) + sum(DF[,9])
c4 <- DF[,4]
c4
c9 <- DF[,9]
c9
c4+c9
sum(c4)
sum(c9)
source('~/.active-rstudio-document')
library(httr)
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readLines(con)
close(con)
htmlCode[10]
source('~/.active-rstudio-document')
library(httr)
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readLines(con)
close(con)
nchar(htmlCode[10])
source('~/.active-rstudio-document')
library(httr)
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readLines(con)
close(con)
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
source('~/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/question5.R')
fileURL <- "http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
#dataDir <- "/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data"
#if (!file.exists(dataDir)) {
#  dir.create(dataDir)
#}
#download.file(fileURL, "/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data/fwf.for")
DF <- read.fwf("/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data/getdata-wksst8110.for",skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(DF)
sum(DF[,4]) + sum(DF[,8])
source('~/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/question5.R')
fileURL <- "http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
#dataDir <- "/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data"
#if (!file.exists(dataDir)) {
#  dir.create(dataDir)
#}
#download.file(fileURL, "/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data/fwf.for")
DF <- read.fwf("/Users/benakiva/Dropbox/Coursera/Getting and Cleaning Data/Week2/quizzes/data/getdata-wksst8110.for",skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(DF)
sum(DF[,4]) + sum(DF[,9])
DF[,9]
c9 <- DF[,9]
c9
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
pack_sum <- summarize(by_package, count = n(), unique = n_distinct(ip_id), countries = n_distinct(country), avg_bytes = mean(size))
pack_sum
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
filter(pack_sum, count > 679)
top_counts <- filter(pack_sum, count > 679)
top_counts
head(top_counts, 20)
arrang(top_counts, desc(count))
arrange(top_counts, desc(count))
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
top_unique
arrange(top_unique, desc(unique))
submit()
submit()
submit()
submit()
submit()
submit()
submit()
bye()
swirl()
?
;
?swirl
swirl()
submit()
sessionInfo()
submit()
library(swirl)
rm(list=ls())
reset()
ls()
install_from_swirl("Getting and Cleaning Data")
swirl()
library(dplyr)
cran <-
;
bye()
source('~/Dropbox/Coursera/Getting and Cleaning Data/swirl/swirl.R')
Sys.getlocale("LC_TIME")
bye
quit()
source('~/Dropbox/Coursera/Getting and Cleaning Data/swirl/swirl.R')
bye()
quit()
source('~/.active-rstudio-document')
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
print(p)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(ggplot2)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
g + geom_points()
g + geom_point()
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies) + geom_smooth()
?trellis.par.set()
setwd("~/Dropbox/Coursera/Exploratory Data Analysis/project2")
source('~/Dropbox/Coursera/Exploratory Data Analysis/project2/plot1.R')
source('~/Dropbox/Coursera/Exploratory Data Analysis/project2/plot1.R')
fileURL <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2FNEI_data.zip"
if (!file.exists("./exdata-data-NEI_data")) {
download.file(fileUrl, "./exdata-data-NEI_data", method = "curl")
}
unz("./exdata-data-NEI_data", "Source_Classification_Code.rds")
unz("./exdata-data-NEI_data", "summarySCC_PM25.rds")
source('~/Dropbox/Coursera/Exploratory Data Analysis/project2/plot1.R')
?readRDS
source('~/.active-rstudio-document')
source('~/Dropbox/Coursera/Exploratory Data Analysis/project2/plot1.R')
?download.file
?plot
source('~/Dropbox/Coursera/Exploratory Data Analysis/project2/plot1.R')
plot(NEI$Emissions, NEI$year)
NEI$Emissions
plot(NEI$year, NEI$Emissions)
plot(NEI$year, as.numeric(NEI$Emissions))
EmissionsTotals <- aggregate(Emissions ~ year, NEI, FUN=sum)
barplot(round(EmissionsTotals[,2]/1000,2), names.arg=EmissionsTotals$year,
xlab="Year",
ylab="PM2.5 Emissions (10^6 Tons)",
main="Total PM2.5 Emissions From All US Sources")
source('~/Dropbox/Coursera/Exploratory Data Analysis/project2/plot1.R')
source('~/Dropbox/Coursera/Exploratory Data Analysis/project2/plot1.R')
dev.copy(png, file = "./plot1.png", width = 560, height = 480)
dev.off()
ls()
rm(list=ls())
ls()
source('~/Dropbox/Coursera/Exploratory Data Analysis/project2/plot2.R')
source('~/Dropbox/Coursera/Exploratory Data Analysis/project2/plot3.R')
source('~/Dropbox/Coursera/Exploratory Data Analysis/project2/plot3.R')
source('~/Dropbox/Coursera/Exploratory Data Analysis/project2/plot3.R')
source('~/Dropbox/Coursera/Exploratory Data Analysis/project2/plot3.R')
library(ggplot2)
NEI <- readRDS("summarySCC_PM25.rds")
SCC <- readRDS("Source_Classification_Code.rds")
# Filter the data for Baltimore
BAData <- NEI[NEI$fips=="24510",]
EmissionsTotals <- aggregate(Emissions ~ year, BAData, FUN=sum)
EmissionsTotals$year <- factor(EmissionsTotals$year, levels=c('1999', '2002', '2005', '2008'))
ggplot(EmissionsTotals, aes(x=year, y=log(Emissions),fill=type)) +
geom_bar(stat="identity") +
theme_bw() + guides(fill=FALSE)+
facet_grid(.~type,scales = "free",space="free") +
labs(x="year", y=expression("Total PM"[2.5]*" Emission (Tons)")) +
labs(title=expression("PM"[2.5]*" Emissions per Type in Baltimore City 1999-2008"))
dev.copy(png, file = "./plot3.png", width = 800, height = 600, units='px')
dev.off()
rm(list=ls())
source('~/Dropbox/Coursera/Exploratory Data Analysis/project2/plot3.R')
library(ggplot2)
NEI <- readRDS("summarySCC_PM25.rds")
SCC <- readRDS("Source_Classification_Code.rds")
# Filter the data for Baltimore
BAData <- NEI[NEI$fips=="24510",]
EmissionsTotals <- aggregate(Emissions ~ year, BAData, FUN=sum)
png(filename="./plot3.png", width=800, height=600, units='px')
ggplot(EmissionsTotals, aes(factor(year), Emissions,fill=type)) +
geom_bar(stat="identity") +
theme_bw() + guides(fill=FALSE)+
facet_grid(.~type,scales = "free",space="free") +
labs(x="year", y=expression("Total PM"[2.5]*" Emission (Tons)")) +
labs(title=expression("PM"[2.5]*" Emissions per Type in Baltimore City 1999-2008"))
dev.off()
rm(list=ls())
source('~/Dropbox/Coursera/Exploratory Data Analysis/project2/plot3.R')
library(ggplot2)
NEI <- readRDS("summarySCC_PM25.rds")
SCC <- readRDS("Source_Classification_Code.rds")
# Filter the data for Baltimore
BAData <- NEI[NEI$fips=="24510",]
EmissionsTotals <- aggregate(Emissions ~ year, BAData, FUN=sum)
BAData$year <- factor(BAData$year, levels=c('1999', '2002', '2005', '2008'))
png(filename="./plot3.png", width=800, height=600, units='px')
ggplot(BAData, aes(x=year, y=log(Emissions),fill=type)) +
geom_bar(stat="identity") +
theme_bw() + guides(fill=FALSE)+
facet_grid(.~type,scales = "free",space="free") +
labs(x="year", y=expression("Total PM"[2.5]*" Emission (Tons)")) +
labs(title=expression("PM"[2.5]*" Emissions per Type in Baltimore City 1999-2008"))
dev.off()
source('~/Dropbox/Coursera/Exploratory Data Analysis/project2/plot3.R')
library(ggplot2)
NEI <- readRDS("summarySCC_PM25.rds")
SCC <- readRDS("Source_Classification_Code.rds")
# Filter the data for Baltimore
BAData <- NEI[NEI$fips=="24510",]
EmissionsTotals <- aggregate(Emissions ~ year, BAData, FUN=sum)
BAData$year <- factor(BAData$year, levels=c('1999', '2002', '2005', '2008'))
png(filename="./plot3.png", width=800, height=600, units='px')
ggplot(BAData, aes(year, Emissions, fill=type)) +
geom_bar(stat="identity") +
theme_bw() + guides(fill=FALSE)+
facet_grid(.~type,scales = "free",space="free") +
labs(x="year", y=expression("Total PM"[2.5]*" Emission (Tons)")) +
labs(title=expression("PM"[2.5]*" Emissions per Type in Baltimore City 1999-2008"))
dev.off()
